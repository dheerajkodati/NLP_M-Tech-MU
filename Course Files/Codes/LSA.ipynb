{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkHRN99fEiTo",
        "outputId": "9c54bcf4-10e1-4539-e6d5-da8b82141a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Top Words in Each Concept (LSA Results):\n",
            "Concept 1:\n",
            "['ai', 'learning', 'machine', 'industries', 'transforming']\n",
            "\n",
            "Concept 2:\n",
            "['cats', 'lot', 'love', 'sleep', 'future']\n",
            "\n",
            "\n",
            "ðŸ”¹ Document-Concept Matrix:\n",
            "      Concept 1     Concept 2  \\\n",
            "0  1.406707e-16  9.107667e-17   \n",
            "1  8.192129e-01 -2.463892e-15   \n",
            "2  3.545092e-16 -6.305926e-01   \n",
            "3  3.762879e-01  1.062870e-14   \n",
            "4  3.170959e-16  7.761140e-01   \n",
            "5  8.139025e-01 -2.558177e-15   \n",
            "\n",
            "                                            Document  \n",
            "0                       Cat and dog are common pets.  \n",
            "1  AI and machine learning are transforming indus...  \n",
            "2                            Dogs are loyal animals.  \n",
            "3  Artificial Intelligence (AI) is the future of ...  \n",
            "4                          Cats love to sleep a lot.  \n",
            "5     Machine learning enables AI models to improve.  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Sample documents (you can replace them with real text data)\n",
        "documents = [\n",
        "    \"Cat and dog are common pets.\",\n",
        "    \"AI and machine learning are transforming industries.\",\n",
        "    \"Dogs are loyal animals.\",\n",
        "    \"Artificial Intelligence (AI) is the future of technology.\",\n",
        "    \"Cats love to sleep a lot.\",\n",
        "    \"Machine learning enables AI models to improve.\"\n",
        "]\n",
        "\n",
        "# ðŸ”¹ Step 1: Convert Text to TF-IDF Matrix\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)  # Term-Document Matrix\n",
        "\n",
        "# ðŸ”¹ Step 2: Apply Truncated SVD for LSA\n",
        "num_concepts = 2  # Number of latent topics to extract\n",
        "svd = TruncatedSVD(n_components=num_concepts)\n",
        "X_lsa = svd.fit_transform(X)\n",
        "\n",
        "# ðŸ”¹ Step 3: Display Top Words in Each Concept\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "def print_top_words_per_concept():\n",
        "    for i, comp in enumerate(svd.components_):\n",
        "        terms_in_comp = zip(terms, comp)\n",
        "        sorted_terms = sorted(terms_in_comp, key=lambda x: x[1], reverse=True)[:5]\n",
        "        print(f\"Concept {i+1}:\")\n",
        "        print([term for term, _ in sorted_terms])\n",
        "        print(\"\")\n",
        "\n",
        "# ðŸ”¹ Output Results\n",
        "print(\"\\nðŸ”¹ Top Words in Each Concept (LSA Results):\")\n",
        "print_top_words_per_concept()\n",
        "\n",
        "print(\"\\nðŸ”¹ Document-Concept Matrix:\")\n",
        "df = pd.DataFrame(X_lsa, columns=[f\"Concept {i+1}\" for i in range(num_concepts)])\n",
        "df[\"Document\"] = documents\n",
        "print(df)"
      ]
    }
  ]
}